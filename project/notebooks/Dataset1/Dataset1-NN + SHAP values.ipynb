{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.92\n",
      "precision  : 0.75\n",
      "recall  : 0.71\n",
      "f1 score  : 0.73\n",
      "confusion matrix : \n",
      " [[1041   45]\n",
      " [  55  134]]\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import keras \n",
    "import pydot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import os\n",
    "\n",
    "proccessed_data_path =os.path.join(os.path.pardir,os.path.pardir,'data','processed')\n",
    "train_path = os.path.join(proccessed_data_path,'dataset1.csv')\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "labels=df['Churn']\n",
    "x = df.drop(columns=['Churn','Unnamed: 0'],axis = 'columns')\n",
    "y=np.ravel(labels)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "oversample = SMOTENC(categorical_features=[1, 2,17,18,19])\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "\n",
    "sc = RobustScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.001), input_dim=20, activation='relu' ))\n",
    "nn_model.add(Dropout(rate=0.2))\n",
    "nn_model.add(Dense(8,kernel_regularizer=tf.keras.regularizers.l2(0.001),activation='relu'))\n",
    "nn_model.add(Dropout(rate=0.1))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lr_schedule= tf.keras.optimizers.schedules.InverseTimeDecay( 0.001,\n",
    "      decay_steps=(x_train.shape[0]/32)*50,\n",
    "      decay_rate=1,\n",
    "      staircase=False)\n",
    "\n",
    "def get_optimizer():\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "nn_model.compile(loss = \"binary_crossentropy\", \n",
    "                  optimizer = get_optimizer(), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "callback =tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=70,restore_best_weights=True)\n",
    "history = nn_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=150, batch_size=10,verbose=0,callbacks=[callback])\n",
    "\n",
    "y_pred = nn_model.predict(x_test)\n",
    "\n",
    "print ('accuracy : {0:.2f}'.format(accuracy_score(y_test,y_pred.round())))\n",
    "print ('precision  : {0:.2f}'.format(precision_score(y_test,y_pred.round())))\n",
    "print ('recall  : {0:.2f}'.format(recall_score(y_test,y_pred.round())))\n",
    "print ('f1 score  : {0:.2f}'.format(f1_score(y_test,y_pred.round())))\n",
    "print ('confusion matrix : \\n {0}'.format(confusion_matrix(y_test,y_pred.round())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020631B0E160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020631B0E160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.008735\n",
      "                0.000596\n",
      "                0.000133\n",
      "                0.029818\n",
      "                0.063464\n",
      "                0.013242\n",
      "                0.002136\n",
      "                0.014243\n",
      "                0.018552\n",
      "                0.002674\n",
      "                0.012731\n",
      "                0.021781\n",
      "                0.000412\n",
      "                0.002376\n",
      "                0.005683\n",
      "                0.000219\n",
      "                0.009024\n",
      "                0.000105\n",
      "                0.000377\n",
      "                0.000129\n",
      "Iteration 2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638ACC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638ACC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.007150\n",
      "                0.000939\n",
      "                0.000191\n",
      "                0.025000\n",
      "                0.059029\n",
      "                0.014366\n",
      "                0.002346\n",
      "                0.018820\n",
      "                0.014023\n",
      "                0.003511\n",
      "                0.012375\n",
      "                0.013776\n",
      "                0.000179\n",
      "                0.004249\n",
      "                0.005699\n",
      "                0.000488\n",
      "                0.011286\n",
      "                0.000232\n",
      "                0.000385\n",
      "                0.000208\n",
      "Iteration 3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638B95940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638B95940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.007504\n",
      "                0.003405\n",
      "                0.000540\n",
      "                0.022785\n",
      "                0.067912\n",
      "                0.015689\n",
      "                0.006652\n",
      "                0.012482\n",
      "                0.017621\n",
      "                0.006246\n",
      "                0.008572\n",
      "                0.016974\n",
      "                0.000813\n",
      "                0.005947\n",
      "                0.009560\n",
      "                0.000452\n",
      "                0.020922\n",
      "                0.000566\n",
      "                0.001017\n",
      "                0.000289\n",
      "Iteration 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002063E8E3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002063E8E3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.003218\n",
      "                0.002906\n",
      "                0.000585\n",
      "                0.024795\n",
      "                0.062306\n",
      "                0.013765\n",
      "                0.004583\n",
      "                0.012535\n",
      "                0.015625\n",
      "                0.005704\n",
      "                0.009060\n",
      "                0.017292\n",
      "                0.000461\n",
      "                0.004654\n",
      "                0.007800\n",
      "                0.000338\n",
      "                0.017894\n",
      "                0.000402\n",
      "                0.000594\n",
      "                0.000066\n",
      "Iteration 5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002063E8E3280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002063E8E3280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.009154\n",
      "                0.005166\n",
      "                0.000841\n",
      "                0.020220\n",
      "                0.061788\n",
      "                0.013790\n",
      "                0.008424\n",
      "                0.014823\n",
      "                0.015004\n",
      "                0.007381\n",
      "                0.005965\n",
      "                0.014557\n",
      "                0.000769\n",
      "                0.005956\n",
      "                0.007382\n",
      "                0.000299\n",
      "                0.025692\n",
      "                0.001130\n",
      "                0.000334\n",
      "                0.000424\n",
      "Iteration 6\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002063EBBC310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002063EBBC310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.010569\n",
      "                0.007028\n",
      "                0.001029\n",
      "                0.020526\n",
      "                0.070386\n",
      "                0.018958\n",
      "                0.010541\n",
      "                0.012383\n",
      "                0.016560\n",
      "                0.008130\n",
      "                0.006792\n",
      "                0.017816\n",
      "                0.000563\n",
      "                0.004125\n",
      "                0.008822\n",
      "                0.000209\n",
      "                0.022491\n",
      "                0.001206\n",
      "                0.000972\n",
      "                0.000592\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638730550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638730550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.006146\n",
      "                0.003994\n",
      "                0.000813\n",
      "                0.018930\n",
      "                0.056331\n",
      "                0.012673\n",
      "                0.006254\n",
      "                0.011211\n",
      "                0.011505\n",
      "                0.005654\n",
      "                0.008303\n",
      "                0.012398\n",
      "                0.000252\n",
      "                0.003481\n",
      "                0.007190\n",
      "                0.000098\n",
      "                0.018545\n",
      "                0.001109\n",
      "                0.000469\n",
      "                0.000296\n",
      "Iteration 8\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638B95EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638B95EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.004067\n",
      "                0.004171\n",
      "                0.000730\n",
      "                0.027404\n",
      "                0.079664\n",
      "                0.017537\n",
      "                0.006054\n",
      "                0.014041\n",
      "                0.020160\n",
      "                0.005079\n",
      "                0.004062\n",
      "                0.021254\n",
      "                0.000222\n",
      "                0.002458\n",
      "                0.006084\n",
      "                0.000198\n",
      "                0.016017\n",
      "                0.000767\n",
      "                0.000600\n",
      "                0.000222\n",
      "Iteration 9\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020631124700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020631124700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.003969\n",
      "                0.003118\n",
      "                0.000712\n",
      "                0.016873\n",
      "                0.046184\n",
      "                0.009279\n",
      "                0.005279\n",
      "                0.013233\n",
      "                0.012704\n",
      "                0.004899\n",
      "                0.007694\n",
      "                0.011801\n",
      "                0.000248\n",
      "                0.003240\n",
      "                0.005701\n",
      "                0.000190\n",
      "                0.015600\n",
      "                0.000653\n",
      "                0.000453\n",
      "                0.000218\n",
      "Iteration 10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638ACCD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000020638ACCD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " feature_importance_vals\n",
      "                0.010420\n",
      "                0.003756\n",
      "                0.000804\n",
      "                0.021767\n",
      "                0.061675\n",
      "                0.013072\n",
      "                0.010383\n",
      "                0.014677\n",
      "                0.016065\n",
      "                0.002500\n",
      "                0.008979\n",
      "                0.019442\n",
      "                0.000325\n",
      "                0.006881\n",
      "                0.009240\n",
      "                0.000125\n",
      "                0.018808\n",
      "                0.000457\n",
      "                0.001227\n",
      "                0.000904\n"
     ]
    }
   ],
   "source": [
    "ii = 1\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.001), input_dim=20, activation='relu' ))\n",
    "nn_model.add(Dropout(rate=0.2))\n",
    "nn_model.add(Dense(8,kernel_regularizer=tf.keras.regularizers.l2(0.001),activation='relu'))\n",
    "nn_model.add(Dropout(rate=0.1))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=70,restore_best_weights=True)\n",
    "    \n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in cv.split(x, y):\n",
    "\tprint(\"Iteration\" , ii)\n",
    "\tXi_train, Xi_test = x.loc[train_index], x.loc[test_index]\n",
    "\tyi_train, yi_test = y[train_index], y[test_index]\n",
    "\tlr_schedule= tf.keras.optimizers.schedules.InverseTimeDecay( 0.001,decay_steps=(Xi_train.shape[0]/32)*50,decay_rate=1,staircase=False)\n",
    "\tnn_model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(lr_schedule), metrics=['accuracy'])\n",
    "\tnn_model.fit(Xi_train, yi_train, validation_data=(Xi_test, yi_test), epochs=150, batch_size=10,verbose=0,callbacks=[callback])\n",
    "\texplainer = shap.DeepExplainer(nn_model, Xi_train.to_numpy())\n",
    "\tshap_values = explainer.shap_values(Xi_test.to_numpy())\n",
    "\tvals = np.abs(shap_values[0]).mean(axis=0)\n",
    "\tprint( pd.DataFrame(list(zip(vals)),columns=['feature_importance_vals']).to_string(index=False))\n",
    "\tii += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
