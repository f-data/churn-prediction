{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.149144\n",
      "                      0.201001\n",
      "                      0.289998\n",
      "                      0.277260\n",
      "                      0.493985\n",
      "                      0.878743\n",
      "                      0.168033\n",
      "                      0.515332\n",
      "                      0.277460\n",
      "                      0.286487\n",
      " DT - feature_importance_vals\n",
      "                     0.010848\n",
      "                     0.055477\n",
      "                     0.052878\n",
      "                     0.007685\n",
      "                     0.108218\n",
      "                     0.149173\n",
      "                     0.012846\n",
      "                     0.076044\n",
      "                     0.018985\n",
      "                     0.037511\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000028255AAFAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000028255AAFAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From C:\\Users\\ggj\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:239: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NN - feature_importance_vals\n",
      "                     0.020112\n",
      "                     0.052563\n",
      "                     0.078732\n",
      "                     0.031031\n",
      "                     0.072693\n",
      "                     0.044511\n",
      "                     0.010435\n",
      "                     0.055144\n",
      "                     0.067583\n",
      "                     0.054779\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.176546\n",
      "                      0.212426\n",
      "                      0.290658\n",
      "                      0.283989\n",
      "                      0.501896\n",
      "                      0.861012\n",
      "                      0.210678\n",
      "                      0.508135\n",
      "                      0.270274\n",
      "                      0.303122\n",
      " DT - feature_importance_vals\n",
      "                     0.008399\n",
      "                     0.043171\n",
      "                     0.033727\n",
      "                     0.005417\n",
      "                     0.095265\n",
      "                     0.153352\n",
      "                     0.013379\n",
      "                     0.065966\n",
      "                     0.029185\n",
      "                     0.037097\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x00000282488CAF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x00000282488CAF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.022946\n",
      "                     0.038209\n",
      "                     0.103485\n",
      "                     0.069268\n",
      "                     0.057396\n",
      "                     0.043552\n",
      "                     0.019100\n",
      "                     0.024238\n",
      "                     0.041877\n",
      "                     0.062361\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.161361\n",
      "                      0.233060\n",
      "                      0.271829\n",
      "                      0.269572\n",
      "                      0.485693\n",
      "                      0.893820\n",
      "                      0.160195\n",
      "                      0.470481\n",
      "                      0.260403\n",
      "                      0.279511\n",
      " DT - feature_importance_vals\n",
      "                     0.014917\n",
      "                     0.049675\n",
      "                     0.049482\n",
      "                     0.005567\n",
      "                     0.092605\n",
      "                     0.152624\n",
      "                     0.008714\n",
      "                     0.072834\n",
      "                     0.027760\n",
      "                     0.032905\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x00000282573A9B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x00000282573A9B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.028795\n",
      "                     0.026788\n",
      "                     0.080558\n",
      "                     0.053625\n",
      "                     0.069737\n",
      "                     0.038764\n",
      "                     0.010088\n",
      "                     0.019318\n",
      "                     0.035444\n",
      "                     0.037694\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.175434\n",
      "                      0.244833\n",
      "                      0.264855\n",
      "                      0.236743\n",
      "                      0.488510\n",
      "                      0.908755\n",
      "                      0.170890\n",
      "                      0.487272\n",
      "                      0.296639\n",
      "                      0.274987\n",
      " DT - feature_importance_vals\n",
      "                     0.007034\n",
      "                     0.045368\n",
      "                     0.032323\n",
      "                     0.012675\n",
      "                     0.083869\n",
      "                     0.150846\n",
      "                     0.011886\n",
      "                     0.056592\n",
      "                     0.028531\n",
      "                     0.031428\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825A0A4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825A0A4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.025553\n",
      "                     0.025751\n",
      "                     0.071925\n",
      "                     0.040353\n",
      "                     0.069696\n",
      "                     0.048183\n",
      "                     0.025318\n",
      "                     0.020313\n",
      "                     0.036026\n",
      "                     0.054749\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.150075\n",
      "                      0.250792\n",
      "                      0.277442\n",
      "                      0.262584\n",
      "                      0.514470\n",
      "                      0.880469\n",
      "                      0.171683\n",
      "                      0.512595\n",
      "                      0.266920\n",
      "                      0.271297\n",
      " DT - feature_importance_vals\n",
      "                     0.012063\n",
      "                     0.046622\n",
      "                     0.052929\n",
      "                     0.017987\n",
      "                     0.083632\n",
      "                     0.151908\n",
      "                     0.010824\n",
      "                     0.067601\n",
      "                     0.019549\n",
      "                     0.031884\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825A0A4820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825A0A4820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.020901\n",
      "                     0.039129\n",
      "                     0.046139\n",
      "                     0.050312\n",
      "                     0.054536\n",
      "                     0.042285\n",
      "                     0.024072\n",
      "                     0.017654\n",
      "                     0.041738\n",
      "                     0.054286\n",
      "Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.153193\n",
      "                      0.240879\n",
      "                      0.318965\n",
      "                      0.241637\n",
      "                      0.519956\n",
      "                      0.811496\n",
      "                      0.161543\n",
      "                      0.558641\n",
      "                      0.270837\n",
      "                      0.291504\n",
      " DT - feature_importance_vals\n",
      "                     0.006648\n",
      "                     0.037890\n",
      "                     0.032470\n",
      "                     0.011795\n",
      "                     0.080270\n",
      "                     0.162322\n",
      "                     0.009161\n",
      "                     0.050261\n",
      "                     0.028276\n",
      "                     0.028622\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x00000282573A9CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x00000282573A9CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.020278\n",
      "                     0.032641\n",
      "                     0.061002\n",
      "                     0.028268\n",
      "                     0.061314\n",
      "                     0.040012\n",
      "                     0.026919\n",
      "                     0.027311\n",
      "                     0.040327\n",
      "                     0.032933\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.161900\n",
      "                      0.246297\n",
      "                      0.276362\n",
      "                      0.249716\n",
      "                      0.501618\n",
      "                      0.867380\n",
      "                      0.145868\n",
      "                      0.510727\n",
      "                      0.275937\n",
      "                      0.303306\n",
      " DT - feature_importance_vals\n",
      "                     0.007950\n",
      "                     0.038140\n",
      "                     0.031160\n",
      "                     0.013379\n",
      "                     0.087340\n",
      "                     0.156575\n",
      "                     0.011279\n",
      "                     0.051909\n",
      "                     0.032557\n",
      "                     0.027873\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000028255E90790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000028255E90790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.012213\n",
      "                     0.027760\n",
      "                     0.031148\n",
      "                     0.026431\n",
      "                     0.054284\n",
      "                     0.038816\n",
      "                     0.027637\n",
      "                     0.027206\n",
      "                     0.036082\n",
      "                     0.051314\n",
      "Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.168951\n",
      "                      0.239558\n",
      "                      0.246474\n",
      "                      0.247594\n",
      "                      0.506338\n",
      "                      0.912840\n",
      "                      0.157778\n",
      "                      0.475113\n",
      "                      0.298994\n",
      "                      0.293341\n",
      " DT - feature_importance_vals\n",
      "                     0.011825\n",
      "                     0.037607\n",
      "                     0.030662\n",
      "                     0.008657\n",
      "                     0.087058\n",
      "                     0.150453\n",
      "                     0.010297\n",
      "                     0.053840\n",
      "                     0.026556\n",
      "                     0.031689\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825A41B040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825A41B040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.018339\n",
      "                     0.040802\n",
      "                     0.043328\n",
      "                     0.039171\n",
      "                     0.064028\n",
      "                     0.048268\n",
      "                     0.015226\n",
      "                     0.034081\n",
      "                     0.056018\n",
      "                     0.047124\n",
      "Iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.174431\n",
      "                      0.241078\n",
      "                      0.313394\n",
      "                      0.246865\n",
      "                      0.517144\n",
      "                      0.834255\n",
      "                      0.172416\n",
      "                      0.539587\n",
      "                      0.266916\n",
      "                      0.284566\n",
      " DT - feature_importance_vals\n",
      "                     0.009311\n",
      "                     0.044744\n",
      "                     0.048284\n",
      "                     0.014090\n",
      "                     0.085303\n",
      "                     0.156525\n",
      "                     0.010104\n",
      "                     0.065774\n",
      "                     0.019279\n",
      "                     0.031530\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825D3BC550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002825D3BC550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.020031\n",
      "                     0.028477\n",
      "                     0.035400\n",
      "                     0.033505\n",
      "                     0.059968\n",
      "                     0.059243\n",
      "                     0.022665\n",
      "                     0.029905\n",
      "                     0.046657\n",
      "                     0.049023\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGB - feature_importance_vals\n",
      "                      0.166038\n",
      "                      0.244939\n",
      "                      0.286089\n",
      "                      0.261079\n",
      "                      0.527737\n",
      "                      0.881183\n",
      "                      0.171464\n",
      "                      0.513362\n",
      "                      0.272168\n",
      "                      0.291035\n",
      " DT - feature_importance_vals\n",
      "                     0.009787\n",
      "                     0.044179\n",
      "                     0.060579\n",
      "                     0.007900\n",
      "                     0.090257\n",
      "                     0.152564\n",
      "                     0.015292\n",
      "                     0.072226\n",
      "                     0.021783\n",
      "                     0.044884\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000028258F87E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x0000028258F87E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " NN - feature_importance_vals\n",
      "                     0.026399\n",
      "                     0.029453\n",
      "                     0.024630\n",
      "                     0.033433\n",
      "                     0.064301\n",
      "                     0.037806\n",
      "                     0.014719\n",
      "                     0.023272\n",
      "                     0.028754\n",
      "                     0.061780\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shap\n",
    "from numpy import mean\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import keras \n",
    "import pydot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import shap\n",
    "\n",
    "#Read data\n",
    "proccessed_data_path =os.path.join(os.path.pardir,os.path.pardir,'data','processed')\n",
    "train_path = os.path.join(proccessed_data_path,'dataset4.csv')\n",
    "df = pd.read_csv(train_path)\n",
    "labels=df['Churn']\n",
    "x = df.drop(columns=['Churn','Unnamed: 0'],axis = 'columns')\n",
    "y=np.ravel(labels)\n",
    "oversample = SMOTENC(categorical_features=[1,2])\n",
    "x, y = oversample.fit_resample(x, y)\n",
    "sc = RobustScaler()\n",
    "x = pd.DataFrame(sc.fit_transform(x),columns = x.columns)\n",
    "\n",
    "ii = 1\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=1,learning_rate=0.05, max_depth=7,eval_metric='mlogloss',use_label_encoder =False ,objective=\"binary:logistic\")\n",
    "dt_model=DecisionTreeClassifier(random_state=1,criterion='entropy',max_depth = 7,min_samples_leaf=30)  \n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.001), input_dim=10, activation='relu' ))\n",
    "nn_model.add(Dropout(rate=0.2))\n",
    "nn_model.add(Dense(8,kernel_regularizer=tf.keras.regularizers.l2(0.001),activation='relu'))\n",
    "nn_model.add(Dropout(rate=0.1))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=70,restore_best_weights=True)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in cv.split(x, y):\n",
    "\tprint(\"Iteration\" , ii)\n",
    "\tXi_train, Xi_test = x.loc[train_index], x.loc[train_index]\n",
    "\tyi_train, yi_test = y[train_index], y[test_index]\n",
    "\txgb_model.fit(Xi_train,yi_train)\n",
    "\tshap_values = shap.TreeExplainer(xgb_model).shap_values(Xi_test,approximate=True)\n",
    "\t#shap.summary_plot(shap_values, Xi_test, plot_type=\"bar\")\n",
    "\tvals = np.abs(shap_values).mean(axis=0)\n",
    "\tprint(pd.DataFrame(list(zip(vals)),columns=['XGB - feature_importance_vals']).to_string(index=False))    \n",
    "\tXi_train, Xi_test = x.loc[train_index], x.loc[test_index]\n",
    "\tyi_train, yi_test = y[train_index], y[test_index]\n",
    "\tdt_model.fit(Xi_train,yi_train)\n",
    "\texplainer = shap.TreeExplainer(dt_model)\n",
    "\tshap_values = explainer.shap_values(Xi_test)\n",
    "\t#shap.summary_plot(shap_values[1], Xi_test, plot_type=\"bar\")\n",
    "\tvals = np.abs(shap_values[1]).mean(axis=0)\n",
    "\tprint( pd.DataFrame(list(zip(vals)),columns=['DT - feature_importance_vals']).to_string(index=False))\n",
    "\tlr_schedule= tf.keras.optimizers.schedules.InverseTimeDecay( 0.001,decay_steps=(Xi_train.shape[0]/32)*50,decay_rate=1,staircase=False)\n",
    "\tnn_model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(lr_schedule), metrics=['accuracy'])\n",
    "\tnn_model.fit(Xi_train, yi_train, validation_data=(Xi_test, yi_test), epochs=150, batch_size=10,verbose=0,callbacks=[callback])\n",
    "\texplainer = shap.DeepExplainer(nn_model, Xi_train[1:100].to_numpy())\n",
    "\tshap_values = explainer.shap_values(Xi_test[1:20].to_numpy())\n",
    "\tvals = np.abs(shap_values[0]).mean(axis=0)\n",
    "\tprint( pd.DataFrame(list(zip(vals)),columns=['NN - feature_importance_vals']).to_string(index=False))\n",
    "\tii += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
